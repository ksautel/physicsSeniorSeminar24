{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Load data\n",
    "path = Path('/Users/katesautel/Documents/Seminar_2024/rel_z.csv')\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# Split data into features (F) and target (T)\n",
    "F = df.iloc[:-1, 0:5]\n",
    "T = df.iloc[:-1, 5]\n",
    "\n",
    "\n",
    "# Scale features to be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "F_scaled = scaler.fit_transform(F)\n",
    "\n",
    "\n",
    "# Convert data from arrays into tensors\n",
    "F_tensor = torch.FloatTensor(F_scaled)\n",
    "T_tensor = torch.FloatTensor(T.values)\n",
    "\n",
    "\n",
    "# Combine F and T into single dataset\n",
    "data = TensorDataset(F_tensor, T_tensor)\n",
    "\n",
    "\n",
    "# Determine training vs. test set split (50%/50%)\n",
    "train_size = len(data) // 2\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "\n",
    "# Randomly split data into train and test\n",
    "train_data, test_data = random_split(dataset = data, lengths = [train_size, test_size])\n",
    "\n",
    "\n",
    "# Define neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_input_features, num_hidden_neurons, num_hidden_layers):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(num_input_features, num_hidden_neurons)\n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(num_hidden_neurons, num_hidden_neurons) for n in range(num_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(num_hidden_neurons, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    num_hidden_neurons = trial.suggest_int('num_hidden_neurons', 16, 256)\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00001, 0.1, log = True)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 0, 500)\n",
    "    momentum = trial.suggest_float('momentum', 0, 1)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = NeuralNetwork(num_input_features = 5,\n",
    "                          num_hidden_neurons = num_hidden_neurons, \n",
    "                          num_hidden_layers = num_hidden_layers)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate model performance\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_true = [] \n",
    "        y_pred = []\n",
    "        for inputs, targets in test_dl:\n",
    "            outputs = model(inputs)\n",
    "            y_true.extend(targets.numpy())\n",
    "            y_pred.extend(outputs.numpy().squeeze())\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# Optuna study\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(objective, n_trials = 100)\n",
    "\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = study.best_params\n",
    "num_hidden_neurons = best_params['num_hidden_neurons']\n",
    "num_hidden_layers = best_params['num_hidden_layers']\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "\n",
    "# Train model with best hyperparameters\n",
    "model = NeuralNetwork(num_input_features = 5, \n",
    "                      num_hidden_neurons = num_hidden_neurons, \n",
    "                      num_hidden_layers = num_hidden_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
